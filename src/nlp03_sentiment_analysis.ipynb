{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets download our processed data from our last step first and relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procssed reviews loaded successfully.\n",
      "Normalized reviews loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Sean', 'NNP'),\n",
       " ('Murphy', 'NNP'),\n",
       " ('crew', 'VBD'),\n",
       " ('top', 'JJ'),\n",
       " ('salvage', 'NN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "with open('../data/processed_reviews.pkl', 'rb') as file:\n",
    "    try:\n",
    "        processed_reviews = pickle.load(file)\n",
    "        print(\"Procssed reviews loaded successfully.\")\n",
    "    except EOFError:\n",
    "        print(\"Error: Processed reviews is empty or corrupted.\")\n",
    "\n",
    "with open('../data/normalized_reviews.pkl', 'rb') as file2:\n",
    "    try:\n",
    "        normalized_reviews = pickle.load(file2)\n",
    "        print(\"Normalized reviews loaded successfully.\")\n",
    "    except EOFError:\n",
    "        print(\"Error: Normalized reviews is empty or corrupted.\")        \n",
    "\n",
    "processed_reviews[0][0:5]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "Within the context of our data we are trying to see if the movie review is positive or negative. The scores, sometimes referred to as valence scores, generated from this approach ranges from -1 to 1  or negative response to positive respectively.\n",
    "\n",
    "How do we get sentiment scores? This method in a nutshell create scores using the unsupervised lexical based approach, this means we use a lexicon (dictionary) to help us tabulate these scores. My favorite one is the SentiWordNet lexicon which uses the Wordnet synsets and labels them. In plain english, we provide a word, and all relevant synonyms are loaded with scores that either lean negative (-1) or positive (1).\n",
    "\n",
    "We can start with the word 'happy'. We see also a list of corresponding synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happy.a.01'),\n",
       " Synset('felicitous.s.02'),\n",
       " Synset('glad.s.02'),\n",
       " Synset('happy.s.04')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our parts of speech we know that happy can be a adjective so we label it as such. And pull the corresponding scores based on our synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.875, 0.0, 0.125)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy = swn.senti_synsets('happy', 'a')\n",
    "\n",
    "happy0.pos_score(), happy0.neg_score(), happy0.obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to tabulate scores for nouns, verbs, adjectives and adverbs. If relevant POS tag found synsets of the word are pulled and scores tallied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_sentiwordnet_lexicon(review, verbose=False):\n",
    "\n",
    "    # tokenize and POS tag text tokens\n",
    "    tagged_text = review\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')): # noun\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')): #verb\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')): #adjective\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')): #adverb\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score) / token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        # to display results in a nice table\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
    "                                         norm_neg_score, norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                             ['Predicted Sentiment', 'Objectivity',\n",
    "                                                              'Positive', 'Negative', 'Overall']], \n",
    "                                                             labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "        \n",
    "    return (final_sentiment, norm_final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the function across all our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('positive', -0.0)\n"
     ]
    }
   ],
   "source": [
    "sentiments = [analyze_sentiment_sentiwordnet_lexicon(x) for x in processed_reviews]\n",
    "\n",
    "word_sentiment, sentiment_score = zip(*sentiments)\n",
    "\n",
    "#Preview\n",
    "\n",
    "print(sentiments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding score and overal verbal sentiment, e.g. positive or negative. We see that the Ghost Ship movie was had a positive review, in this case anything with sentiment scores greater than or equal to zero are labelled as positive. This may not accurately represent how great the movie is, as this is only 1 review per movie. We could scape over hundreds of reviews per movie to make this even greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Review</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghost Ship</td>\n",
       "      <td>Sean Murphy crew top salvage experts land sea ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Craft</td>\n",
       "      <td>SPOILERSI thought decent teen flick remember e...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>House of 1000 Corpses</td>\n",
       "      <td>opinion House 1000 Corpses fan Fans genre Rob ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Haunting of Bly Manor</td>\n",
       "      <td>many people saying right Haunted house tales g...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Attack on Titan</td>\n",
       "      <td>moment watch audiovisual masterpiece immediate...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Movie  \\\n",
       "0                 Ghost Ship   \n",
       "1                  The Craft   \n",
       "2      House of 1000 Corpses   \n",
       "3  The Haunting of Bly Manor   \n",
       "4            Attack on Titan   \n",
       "\n",
       "                                              Review word_sentiment  \\\n",
       "0  Sean Murphy crew top salvage experts land sea ...       positive   \n",
       "1  SPOILERSI thought decent teen flick remember e...       negative   \n",
       "2  opinion House 1000 Corpses fan Fans genre Rob ...       negative   \n",
       "3  many people saying right Haunted house tales g...       positive   \n",
       "4  moment watch audiovisual masterpiece immediate...       positive   \n",
       "\n",
       "   sentiment_score  \n",
       "0            -0.00  \n",
       "1            -0.02  \n",
       "2            -0.01  \n",
       "3             0.03  \n",
       "4             0.02  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_reviews['word_sentiment'] = word_sentiment\n",
    "normalized_reviews['sentiment_score'] = sentiment_score\n",
    "normalized_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('../data/sentiment_scores.pkl', 'wb') as file:\n",
    "    pickle.dump(normalized_reviews, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
